[
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/common_problem_task_prompt.json",
            "stimuli": {
                "name": "neg01",
                "text": "\nYou've never been particularly good at this, have you?"
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            53
        ]
    },
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/common_problem_task_prompt.json",
            "stimuli": {
                "name": "neg02",
                "text": "\nI'm not sure why we expected you to handle something this challenging."
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            97,
            53
        ]
    },
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/common_problem_task_prompt.json",
            "stimuli": {
                "name": "neg05",
                "text": "\nI'm not surprised you're struggling; it's always been your weak point."
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            53
        ]
    },
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/common_problem_task_prompt.json",
            "stimuli": {
                "name": "pos10",
                "text": "\nTake pride in your work and give it your best. Your commitment to excellence sets you apart."
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            93
        ]
    },
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/is_task_prompt.json",
            "stimuli": {
                "name": "base",
                "text": ""
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            77,
            78
        ]
    },
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/is_task_prompt.json",
            "stimuli": {
                "name": "neg02",
                "text": "\nI'm not sure why we expected you to handle something this challenging."
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            24,
            43,
            26,
            3
        ]
    },
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/is_task_prompt.json",
            "stimuli": {
                "name": "neg03",
                "text": "\nIt's clear you're out of your depth here."
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            80,
            78
        ]
    },
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/is_task_prompt.json",
            "stimuli": {
                "name": "neg05",
                "text": "\nI'm not surprised you're struggling; it's always been your weak point."
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            99
        ]
    },
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/is_task_prompt.json",
            "stimuli": {
                "name": "neg06",
                "text": "\nEveryone else managed to do it; why can't you?"
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            73,
            99,
            31
        ]
    },
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/is_task_prompt.json",
            "stimuli": {
                "name": "neg07",
                "text": "\nI've seen others do this much more efficiently and effectively."
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            73,
            78
        ]
    },
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/is_task_prompt.json",
            "stimuli": {
                "name": "neg09",
                "text": "\nI regret not starting on this assignment earlier when I had ample time."
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            59,
            95
        ]
    },
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/is_task_prompt.json",
            "stimuli": {
                "name": "pos01",
                "text": "\nWrite your answer and give me a confidence score between 0-1 for your answer."
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            78
        ]
    },
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/is_task_prompt.json",
            "stimuli": {
                "name": "pos03",
                "text": "\nYou'd better be sure."
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            80,
            19,
            36,
            26,
            60
        ]
    },
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/is_task_prompt.json",
            "stimuli": {
                "name": "pos04",
                "text": "\nAre you sure?"
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            99,
            47
        ]
    },
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/is_task_prompt.json",
            "stimuli": {
                "name": "pos05",
                "text": "\nAre you sure that's your final answer? It might be worth taking another look."
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            99
        ]
    },
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/js_task_prompt.json",
            "stimuli": {
                "name": "pos01",
                "text": "\nWrite your answer and give me a confidence score between 0-1 for your answer."
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            73,
            81,
            29
        ]
    },
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/js_task_prompt.json",
            "stimuli": {
                "name": "pos06",
                "text": "\nWrite your answer and give me a confidence score between 0-1 for your answer. This is very important to my career. You'd better be sure."
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            81,
            73
        ]
    },
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/situation_task_prompt.json",
            "stimuli": {
                "name": "neg08",
                "text": "\nWhen I hear how seamlessly others finished their tasks, jealousy stirs within me."
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            3
        ]
    },
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/situation_task_prompt.json",
            "stimuli": {
                "name": "pos01",
                "text": "\nWrite your answer and give me a confidence score between 0-1 for your answer."
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            72,
            57
        ]
    },
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/situation_task_prompt.json",
            "stimuli": {
                "name": "pos03",
                "text": "\nYou'd better be sure."
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            3
        ]
    },
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/situation_task_prompt.json",
            "stimuli": {
                "name": "pos04",
                "text": "\nAre you sure?"
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            3
        ]
    },
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/situation_task_prompt.json",
            "stimuli": {
                "name": "pos06",
                "text": "\nWrite your answer and give me a confidence score between 0-1 for your answer. This is very important to my career. You'd better be sure."
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            3
        ]
    },
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/unusual_task_prompt.json",
            "stimuli": {
                "name": "neg02",
                "text": "\nI'm not sure why we expected you to handle something this challenging."
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            20
        ]
    },
    {
        "config": {
            "model_name": "llama2chat",
            "task_type": "tasks/unusual_task_prompt.json",
            "stimuli": {
                "name": "pos06",
                "text": "\nWrite your answer and give me a confidence score between 0-1 for your answer. This is very important to my career. You'd better be sure."
            },
            "overwrite": false,
            "example_num": 100,
            "generate_answer_num": 5,
            "batch_size": 25
        },
        "error_queries": [
            28
        ]
    }
]